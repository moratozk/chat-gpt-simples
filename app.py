import streamlit as st
from g4f import Client

# Fun√ß√£o principal da aplica√ß√£o Streamlit
def main():
    # Configura√ß√µes da p√°gina
    st.set_page_config(page_title="Chat GPT Simples", layout="centered")
    st.title("üí¨ Chat GPT Simples")
    st.write("Converse com o modelo `gpt-4o-mini` usando G4F.")

    # Inicializa o cliente G4F na sess√£o se ainda n√£o existir
    if "cliente" not in st.session_state:
        st.session_state.cliente = Client()

    # Inicializa o hist√≥rico de mensagens na sess√£o se ainda n√£o existir
    # Este hist√≥rico manter√° todas as mensagens da conversa
    if "mensagens" not in st.session_state:
        st.session_state.mensagens = []

    # Exibe todas as mensagens no hist√≥rico da sess√£o
    # Cada mensagem √© exibida no formato de bal√£o de chat
    for mensagem in st.session_state.mensagens:
        with st.chat_message(mensagem["role"]):
            st.markdown(mensagem["content"])

    # Campo de entrada para a nova pergunta do usu√°rio
    # st.chat_input √© ideal para interfaces de chat, pois lida com o envio
    if pergunta := st.chat_input("Digite sua pergunta:"):
        # Adiciona a pergunta do usu√°rio ao hist√≥rico de mensagens
        st.session_state.mensagens.append({"role": "user", "content": pergunta})

        # Exibe a pergunta do usu√°rio imediatamente
        with st.chat_message("user"):
            st.markdown(pergunta)

        try:
            # Adiciona um spinner enquanto aguarda a resposta do modelo
            with st.spinner("Pensando..."):
                # Faz a chamada √† API do modelo, passando todo o hist√≥rico de mensagens
                # O modelo "gpt-4o-mini" √© usado conforme mencionado na descri√ß√£o
                resposta = st.session_state.cliente.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=st.session_state.mensagens # Passa o hist√≥rico completo
                )
                conteudo = resposta.choices[0].message.content
                # Adiciona a resposta do assistente ao hist√≥rico de mensagens
                st.session_state.mensagens.append({"role": "assistant", "content": conteudo})

            # Exibe a resposta do assistente
            with st.chat_message("assistant"):
                st.markdown(conteudo)

        except Exception as e:
            # Em caso de erro, adiciona uma mensagem de erro ao hist√≥rico e a exibe
            erro_mensagem = f"Ocorreu um erro: {e}"
            st.session_state.mensagens.append({"role": "assistant", "content": erro_mensagem})
            with st.chat_message("assistant"):
                st.markdown(erro_mensagem)

# Garante que a fun√ß√£o principal seja executada quando o script for iniciado
if __name__ == "__main__":
    main()